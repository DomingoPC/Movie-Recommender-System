{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Recommender System\n",
    "\n",
    "A recommender system is an algorithm or model that takes in information about a user and suggests an item—new to them—that is likely to be of interest. There are several approaches to building such a system, and this notebook will focus on **content-based methods**. Let's begin by starting the PySpark session:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://127.0.0.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>CBRS</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x263836d3370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import helper_functions as hf\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import FloatType, StringType, ArrayType\n",
    "\n",
    "# Initialize Spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CBRS\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>n_genres</th>\n",
       "      <th>n_production_companies</th>\n",
       "      <th>n_production_countries</th>\n",
       "      <th>n_spoken_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>[Drama, Music]</td>\n",
       "      <td>277216</td>\n",
       "      <td>en</td>\n",
       "      <td>In 1987, five young men, using brutally honest...</td>\n",
       "      <td>21.183077</td>\n",
       "      <td>[New Line Cinema, Universal Pictures, Legendar...</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Story of N.W.A.</td>\n",
       "      <td>Straight Outta Compton</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1381</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>167284</td>\n",
       "      <td>en</td>\n",
       "      <td>This movie portrays three women living in toda...</td>\n",
       "      <td>0.153287</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>None</td>\n",
       "      <td>Viva Algeria</td>\n",
       "      <td>False</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>[Crime, Music, Romance]</td>\n",
       "      <td>298078</td>\n",
       "      <td>en</td>\n",
       "      <td>A merciless hit man rescues a prostitute from ...</td>\n",
       "      <td>0.782841</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Philippines]</td>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>When violence is the only life you know, will ...</td>\n",
       "      <td>Ruined Heart: Another Love Story Between A Cri...</td>\n",
       "      <td>False</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                   genres      id original_language  \\\n",
       "0  False           [Drama, Music]  277216                en   \n",
       "1  False                  [Drama]  167284                en   \n",
       "2  False  [Crime, Music, Romance]  298078                en   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In 1987, five young men, using brutally honest...   21.183077   \n",
       "1  This movie portrays three women living in toda...    0.153287   \n",
       "2  A merciless hit man rescues a prostitute from ...    0.782841   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [New Line Cinema, Universal Pictures, Legendar...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "\n",
       "         production_countries release_date  runtime  ...    status  \\\n",
       "0  [United States of America]   2015-08-13    147.0  ...  Released   \n",
       "1                          []   2004-01-01    113.0  ...  Released   \n",
       "2               [Philippines]   2014-10-24     73.0  ...  Released   \n",
       "\n",
       "                                             tagline  \\\n",
       "0                                The Story of N.W.A.   \n",
       "1                                               None   \n",
       "2  When violence is the only life you know, will ...   \n",
       "\n",
       "                                               title  video  vote_average  \\\n",
       "0                             Straight Outta Compton  False           7.7   \n",
       "1                                       Viva Algeria  False           7.2   \n",
       "2  Ruined Heart: Another Love Story Between A Cri...  False           6.7   \n",
       "\n",
       "   vote_count  n_genres  n_production_companies  n_production_countries  \\\n",
       "0        1381         2                       6                       1   \n",
       "1           3         1                       0                       0   \n",
       "2           7         3                       0                       1   \n",
       "\n",
       "   n_spoken_languages  \n",
       "0                   1  \n",
       "1                   0  \n",
       "2                   2  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Movies Metadata (Load Dataset)\n",
    "df = spark.read.parquet('data/cleaned/movies2/')\n",
    "display(df.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Content-Based Recommender Systems use the metadata of the items and users to give recommendations. In this notebook, the system will recommend movies to watch, so some examples of movie metadata could be movie genres, the name of the director, the production company, popularity, etc. At the same time, users metadata could be use, which include movies previously watched, age and the country they are from.\n",
    "\n",
    "The main advantage of this approach is that in Cold-Start Scenarios—i.e. when there is still not enough user interaction—the system is still capable of giving sensible recommendations. This is due to the fact that metadata is already known—at least for the movies. However, this method does not compute similarity between the users, so the ones with a higher correlation cannot be given a stronger impact in the decision.\n",
    "\n",
    "For the approaches to build a system like this, the options vary depending on the metadata to use or the computation power available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Jaccard and Cosine Similarities\n",
    "> A simple approach and valid when the metadata can be treated as tags, which is common.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "These two are popular similarity metrics that are useful when comparing metadata of various items. For both of them, the first step is to make a matrix $\\underline{\\underline{M}}$ of pairs (movie, tags), where the elements $m_{ij}$ are booleans indicating if the movie *i* has the tag *j*. For example, let's say that there is a DataFrame with two columns, the first the name of the film and the second one of its genres:\n",
    "\n",
    "<center>\n",
    "\n",
    "| **Movie** | **Genre** |\n",
    "|:---------:|:---------:|\n",
    "|     A     |     x     |\n",
    "|     A     |     y     |\n",
    "|     A     |     z     |\n",
    "|     B     |     x     |\n",
    "|     B     |     g     |\n",
    "\n",
    "</center>\n",
    "\n",
    "To transform it into the $\\underline{\\underline{M}}$ matrix, the movies will have to turn into rows and the genres into columns, like such:\n",
    "\n",
    "<center>\n",
    "\n",
    "| **Movie** \\\\ **Genre** | **x** | **y** | **z** | **g** |\n",
    "|------------------------|-------|-------|-------|-------|\n",
    "| **A**                  | 1     | 1     | 1     | 0     |\n",
    "| **B**                  | 1     | 0     | 0     | 1     |\n",
    "\n",
    "</center>\n",
    "\n",
    "Consequently, the elements turn into indicators that show whether the corresponding movie falls under the listed genres. Finally, this allows the movies to be represented as vector—of the space of genres:\n",
    "\n",
    "$$\\underline{A} = (1,1,1,0) \\;\\text{ and }\\; \\underline{B} = (1,0,0,1)$$\n",
    "\n",
    "Now that the movies are expressed as vector, the similarity measure is quite straightforward, as show the following equations:\n",
    "\n",
    "+ **Jaccard Similarity**:   $J(\\underline{A}, \\underline{B}) = \\frac{\\underline{A}\\cap\\underline{B}}{\\underline{A}\\cup\\underline{B}}$\n",
    "\n",
    "+ **Cosine Similarity**:    $Sim(\\underline{B},\\underline{B}) = \\frac{\\underline{A}\\cdot\\underline{B}}{|\\underline{A}||\\underline{B}|}$\n",
    "\n",
    "Coming back to the previous example, the results would be as follows:\n",
    "+ **Jaccard Similarity**:   $J(\\underline{A}, \\underline{B}) = \\frac{(1,1,1,0)\\cap(1,0,0,1)}{(1,1,1,0)\\cup(1,0,0,1)} = \\frac{1+0+0+1}{1+1+1+1} = \\frac{1}{2}$\n",
    "\n",
    "+ **Cosine Similarity**:    $Sim(\\underline{B},\\underline{B}) = \\frac{(1,1,1,0)\\cdot(1,0,0,1)}{|(1,1,1,0)||(1,0,0,1)|} = \\frac{1+0+0+1}{|\\sqrt{1^2+1^2+1^2}||\\sqrt{1^2+1^2}|} = \\sqrt{\\frac{2}{3}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Jaccard and Cosine Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a simple recommender system by movie genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Straight Outta Compton</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Straight Outta Compton</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Viva Algeria</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title  genre\n",
       "0  Straight Outta Compton  Drama\n",
       "1  Straight Outta Compton  Music\n",
       "2            Viva Algeria  Drama"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explode genre list into different columns\n",
    "genres = df.select('genres', 'title')\n",
    "genres = df.select(df.title, f.explode(df.genres).alias('genre'))\n",
    "display(genres.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Straight Outta Compton</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Straight Outta Compton</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Viva Algeria</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title  genre  value\n",
       "0  Straight Outta Compton  Drama      1\n",
       "1  Straight Outta Compton  Music      1\n",
       "2            Viva Algeria  Drama      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a columns of 1 to indicate a movies has a specific genre\n",
    "genres = genres.withColumn('value', f.lit(1))\n",
    "display(genres.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All The Days Before Tomorrow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snowman's Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  Action  Adventure  Animation  Comedy  Crime  \\\n",
       "0                   We Are Many     NaN        NaN        NaN     NaN    NaN   \n",
       "1  All The Days Before Tomorrow     NaN        NaN        NaN     1.0    NaN   \n",
       "2                Snowman's Land     NaN        NaN        NaN     1.0    1.0   \n",
       "\n",
       "   Documentary  Drama  Family  Fantasy  ...  History  Horror  Music  Mystery  \\\n",
       "0          1.0    NaN     NaN      NaN  ...      NaN     NaN    NaN      NaN   \n",
       "1          NaN    1.0     NaN      NaN  ...      NaN     NaN    NaN      NaN   \n",
       "2          NaN    NaN     NaN      NaN  ...      NaN     NaN    NaN      NaN   \n",
       "\n",
       "   Romance  Science Fiction  TV Movie  Thriller  War  Western  \n",
       "0      NaN              NaN       NaN       NaN  NaN      NaN  \n",
       "1      1.0              NaN       NaN       NaN  NaN      NaN  \n",
       "2      NaN              NaN       NaN       1.0  NaN      NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set movies as rows (groupby) and genres as columns (pivot)\n",
    "# sum() makes sure it is one on the (title, genre) pairs indicated above\n",
    "genres = genres.groupby('title').pivot('genre').sum('value')\n",
    "display(genres.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All The Days Before Tomorrow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snowman's Land</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  Action  Adventure  Animation  Comedy  Crime  \\\n",
       "0                   We Are Many       0          0          0       0      0   \n",
       "1  All The Days Before Tomorrow       0          0          0       1      0   \n",
       "2                Snowman's Land       0          0          0       1      1   \n",
       "\n",
       "   Documentary  Drama  Family  Fantasy  ...  History  Horror  Music  Mystery  \\\n",
       "0            1      0       0        0  ...        0       0      0        0   \n",
       "1            0      1       0        0  ...        0       0      0        0   \n",
       "2            0      0       0        0  ...        0       0      0        0   \n",
       "\n",
       "   Romance  Science Fiction  TV Movie  Thriller  War  Western  \n",
       "0        0                0         0         0    0        0  \n",
       "1        1                0         0         0    0        0  \n",
       "2        0                0         0         1    0        0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finally, set the NULLs as 0, which indicate that the movie hasn't that genre\n",
    "genres = genres.fillna(0)\n",
    "display(genres.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame stores the movie-genre relationships, which are required to calculate the similarities. In this scenario, it is a good idea to preemptively calculate similarities and cache them, so the recommendations can happen in real time. To do this, the first step is to turn the movies into vectors, which is an easy task considering the rows of the movie-genre DataFrame is a vector representation of the movies in the genre space. However, to save up memory, it is wise to use dense vectors, because most of the values are zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------+\n",
      "|title                       |features                   |\n",
      "+----------------------------+---------------------------+\n",
      "|We Are Many                 |(20,[5],[1.0])             |\n",
      "|All The Days Before Tomorrow|(20,[3,6,14],[1.0,1.0,1.0])|\n",
      "|Snowman's Land              |(20,[3,4,17],[1.0,1.0,1.0])|\n",
      "+----------------------------+---------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# Train vector assembler on the dataframe\n",
    "vector_assembler = VectorAssembler(inputCols=genres.columns[1:],\n",
    "                                   outputCol='features')\n",
    "\n",
    "# Create the column features with the Dense Vector representation\n",
    "movie_features = vector_assembler.transform(genres).select('title', 'features')\n",
    "movie_features.show(3, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although in pandas, dense vectors show like usual vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All The Days Before Tomorrow</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snowman's Land</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0                   We Are Many   \n",
       "1  All The Days Before Tomorrow   \n",
       "2                Snowman's Land   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(movie_features.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to calculate the similarities for each pair of movies, let's join the resulting DataFrame with itself. This will result into a DataFrame whose rows will contain two movies—thus, two dense vectors. However, there are two things that must be guaranteed:\n",
    "\n",
    "+ For every row, the two movies cannot be the same. This would lead to the calculation of the similarity between them, which will not do any good to the recommender system.\n",
    "\n",
    "+ The pair (A,B) yields the same similarity than the pair (B,A), so there is no need to calculate them both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>All The Days Before Tomorrow</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>Snowman's Land</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                           features  \\\n",
       "0  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "2  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                          title  \\\n",
       "0                   We Are Many   \n",
       "1  All The Days Before Tomorrow   \n",
       "2                Snowman's Land   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cross Join: Cartesian Product of the tables\n",
    "df_cross = movie_features.alias('left').crossJoin(movie_features.alias('right'))\n",
    "display(df_cross.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter out the rows with the same movie twice and the repeated pairs, Python allows the use of '<' to compare text. For example:\n",
    "\n",
    "+ 'The Hunger Games' < 'Braveheart' = False.\n",
    "\n",
    "+ 'Braveheart' < 'The Hunger Games' = True.\n",
    "\n",
    "Because 'B' comes before 'T', due to the alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>What No One Knows</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>What Have They Done to Your Daughters?</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>We are the tide</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                           features  \\\n",
       "0  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "2  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                    title  \\\n",
       "0                       What No One Knows   \n",
       "1  What Have They Done to Your Daughters?   \n",
       "2                         We are the tide   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cross = df_cross.filter(f.col('left.title') < f.col('right.title'))\n",
    "display(df_cross.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the similarities will be stored in a new column and calculated via User Defined Functions (udf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>What No One Knows</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>What Have They Done to Your Daughters?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>We are the tide</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Window Water Baby Moving</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Wood Job!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Zodiac: The Race Begins...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Убить дракона</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Women of the Night</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Wise Guys</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>You Wont Miss Me</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                   title  jaccard  cosine\n",
       "0  We Are Many                       What No One Knows      0.0     0.0\n",
       "1  We Are Many  What Have They Done to Your Daughters?      0.0     0.0\n",
       "2  We Are Many                         We are the tide      0.0     0.0\n",
       "3  We Are Many                Window Water Baby Moving      1.0     1.0\n",
       "4  We Are Many                               Wood Job!      0.0     0.0\n",
       "5  We Are Many              Zodiac: The Race Begins...      0.0     0.0\n",
       "6  We Are Many                           Убить дракона      0.0     0.0\n",
       "7  We Are Many                      Women of the Night      0.0     0.0\n",
       "8  We Are Many                               Wise Guys      0.0     0.0\n",
       "9  We Are Many                        You Wont Miss Me      0.0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Jaccard Similarity ---\n",
    "def jaccard_similarity(v1, v2):\n",
    "    # Formula:\n",
    "    #   J = Intersection(A,B) / Union(A,B)\n",
    "    A_and_B = sum(1 for (a,b) in zip(v1,v2) if a==1 and a==b) # Intersection\n",
    "    A_or_B = sum(1 for (a,b) in zip(v1,v2) if a==1 or b==1) # Union\n",
    "    return float(A_and_B) / A_or_B if A_or_B != 0 else 0.0 # Similarity\n",
    "\n",
    "# --- Cosine Similarity ---\n",
    "def cosine_similarity(v1,v2):\n",
    "    # Formula:\n",
    "    #   Sim = A·B / |A||B|\n",
    "\n",
    "    # Numerator: scalar product\n",
    "    num = sum(c1*c2 for (c1,c2) in zip(v1,v2))\n",
    "    \n",
    "    # Denominator: modules\n",
    "    mod_a = np.sqrt(sum(c1**2 for c1 in v1))\n",
    "    mod_b = np.sqrt(sum(c2**2 for c2 in v2))\n",
    "    den = mod_a * mod_b\n",
    "\n",
    "    # Similarity\n",
    "    return float(num) / float(den) if den != 0.0 else 0.0\n",
    "\n",
    "# --- User Defined Functions ---\n",
    "jaccard_udf = f.udf(lambda v1,v2: jaccard_similarity(v1,v2), FloatType())\n",
    "cosine_udf = f.udf(lambda v1,v2: cosine_similarity(v1,v2), FloatType())\n",
    "\n",
    "# Apply udf to the pairs of movies in every row\n",
    "df_similarities = df_cross.\\\n",
    "    withColumn('jaccard', jaccard_udf(f.col('left.features'), f.col('right.features'))).\\\n",
    "    withColumn('cosine', cosine_udf(f.col('left.features'), f.col('right.features'))).\\\n",
    "    select('left.title', 'right.title', 'jaccard', 'cosine')\n",
    "\n",
    "display(df_similarities.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    ">An appropriate approach when the metadata is text-based, which could enclose additional information not represented in tags. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say there is term *t* in a document *d*, which is part of a collection of documents—or corpus—called *D*. Then the *Term Frequency* or $TF(t,d)$ is defined as the number of times a term *t* appears in a document *d*. This can be used on its own as a way to vectorize documents, but it is very easy to **over-emphasize terms** that appear often yet **carry very little information**, such as the terms 'a', 'the' and 'of'. To counter this issue, every term should be weighted by its 'importance' or its ability to uniquely identify a specific document. \n",
    "\n",
    "To obtain a measure of the importance of every term, firstly it is necessary to define the *Document Frequency* or $DF(t,D)$, which is the number of documents in the corpus *D* that contain the term *t*. According to this, the higher the value of $DF(t,D)$, the lower the importance of *t*, because it doesn't **point to a specific document**. Consequently, a low value in $DF(t,D)$ would indicate that the term *t* carries special information about a particular document, thus the interest is in minimizing this value or alternatively in **maximizing the inverse** of $DF(t,D)$, which can be defined as:\n",
    "\n",
    "$$IDF(t,D) = \\log\\left( \\frac{|D| + 1}{DF(t,D) + 1} \\right),$$\n",
    "\n",
    "where: \n",
    "\n",
    "+ $|D|$ is the total number of documents in the corpus *D*.\n",
    "\n",
    "+ The $+1$ in the denominator is a smoothing factor that avoids dividing by zero, which happens when the term *t* does not appear in any document *D*.\n",
    "\n",
    "+ The $+1$ in the numerator is necessary to avoid computing $\\log(0)$, which can happen if there is no document in the corpus *D*.\n",
    "\n",
    "Note that this equation succeeds in representing the importance of a term *t*, because when a term *t* appears in all documents of *D*, then $|D| = DF(t,D)$, thus $IDF(t,D) = \\log(1) = 0$, whereas the lower $DF(t,D)$ is, the greater the value of $IDF(t,D)$.\n",
    "\n",
    "Finally, the *TF-IDF* measure is calculated following:\n",
    "\n",
    "$$TFIDF(t,d,D) = TF(t,d)\\, IDF(t,D).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In code, the process is similar, if done in a simplistic manner:\n",
    "\n",
    "1. **Tokenization of text:** split sentences into individual words and stored in lists.\n",
    "\n",
    "2. **Compute TF:** using *CountVectorizer* or *HashingTF*—more about them later—, calculate the term frequency for every word and store the resulting list in a new column.\n",
    "\n",
    "3. **Compute IDF:** take the column where the TF is stored—i.e. previous output—and apply IDF to *scale the values* according to term importance.\n",
    "\n",
    "4. **Computing Similarity:** with the vectorize version of the the documents via TF-IDF, similarity can be calculated like in the previous section.\n",
    "\n",
    "However, it is possible to perform additional actions to **improve the quality of the documents**, leading to better results in a more efficient way:\n",
    "\n",
    "1. **Text preprocessing:** cleaning the documents. This includes converting to lowercase, removing punctuation and special characters—so that for example, 'word' and 'word.' are treated equally—, and removing numeric values.\n",
    "\n",
    "2. **Tokenization.**\n",
    "\n",
    "3. **Removing stopwords:** common words, such as 'a', 'the' and 'of', will receive a low IDF score in most cases, so removing them just accelerates the process.\n",
    "\n",
    "4. **Optional, but costly options:**\n",
    "\n",
    "    + **Stemming:** reduces words to their root. E.g. 'running' turns into 'run'.\n",
    "\n",
    "    + **Lemmatization:** finds the dictionary form of words. E.g. 'better' turns into 'good'.\n",
    "\n",
    "5. **Computing TF.**\n",
    "\n",
    "6. **Computing IDF.**\n",
    "\n",
    "7. **Computing Similarity.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About CountVectorizer and HashingTF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Both *CountVetorizer* and *HashingTF* can be used to generate the $TF(t,d)$ values, thus vectorizing the document based on its terms. However, they are fundamentally different approaches, starting with their definitions:\n",
    "\n",
    "+ **CountVectorizer:** It is a feature extraction method that converts text documents into a sparse matrix of term counts. To do this, firstly it *builds a vocabulary* of all unique terms in the corpus *D* and then counts occurrences of each term in every document. This approach is useful when it is necessary to *keep track of words* and their frequencies.\n",
    "\n",
    "+ **HashingTF:** It is a transformation that *maps terms* into a fixed-length feature vector *using a hashing function*. Instead of building a vocabulary, it applies a hash function to each term and assigns it to a predefined number of features, also called 'buckets'. This allows for *efficient computation* in exchange of interpretability, since different terms might hash to the same index (*hash collision*).\n",
    "\n",
    "Moreover, let's discuss some specific differences between the two:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "    <tr>\n",
    "        <th>Feature</th>\n",
    "        <th>CountVectorizer</th>\n",
    "        <th>HashingTF</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Interpretability</b></td>\n",
    "        <td>Keeps the actual words in the vocabulary, making it easy to understand which words contribute to a document.</td>\n",
    "        <td>The words are hashed, so we lose the ability to interpret which word corresponds to which feature.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Memory Usage</b></td>\n",
    "        <td>Requires storing the vocabulary, which can be large for big datasets.</td>\n",
    "        <td>Uses a fixed-length vector, reducing memory requirements since it does not store the vocabulary.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Computational Overhead</b></td>\n",
    "        <td>Requires an extra step to scan the dataset and build the vocabulary before transforming text into vectors.</td>\n",
    "        <td>Directly transforms text using a hashing function, i.e. it can transform the documents in one pass.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Handling of New Words</b></td>\n",
    "        <td>If a new word appears that was not in the training data, it will be ignored (unless vocabulary expansion is allowed).</td>\n",
    "        <td>Can handle new words dynamically without needing retraining.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Risk of Collisions</b></td>\n",
    "        <td>No risk; each word has a unique index.</td>\n",
    "        <td>Has a small chance of hash collisions where different words map to the same index, potentially reducing accuracy.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Scalability</b></td>\n",
    "        <td>May struggle with very large datasets due to vocabulary size constraints.</td>\n",
    "        <td>More scalable since it does not require storing or updating a vocabulary.</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, it is possible to summarize this information focusing on their use cases:\n",
    "\n",
    "+ **CountVectorizer:** recommended if *interpretability* is important and there is enough memory to store the vocabulary.\n",
    "\n",
    "+ **HashingTF:** more optimized for larger datasets, especially when *memory efficiency* is required, and when *new words* are expected frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the dataset, only the *movie_id*, *title* and *overview* will be chosen. The terms in the overviews will yield the TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Shadows in Paradise</td>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                title                                           overview\n",
       "0   2                Ariel  Taisto Kasurinen is a Finnish coal miner whose...\n",
       "1   3  Shadows in Paradise  An episode in the life of Nikander, a garbage ...\n",
       "2   5           Four Rooms  It's Ted the Bellhop's first night on the job...."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overview = df.select('id', 'title', 'overview').orderBy('id').na.drop(subset=[\"overview\"])\n",
    "display(overview.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's focus on transforming the data to make the process more efficient and vectorize the documents. As it was established before, this should include: preprocessing, tokenization, removing stopwords and computing both TF and IDF. *PySpark* can manage most of these, but for the preprocessing is required a specific behavior, thus the best approach would be to implement a custom stage for the pipeline.\n",
    "\n",
    "To create a custom stage for a pipeline one option is to create an user defined function (udf), but the preprocessing stage is slightly complex, as it must convert the text to lowercase and remove any punctuation and special characters. For this reason, a more elegant solution is to use **custom Transformers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol\n",
    "import re\n",
    "\n",
    "class TextPreprocessing(Transformer, HasInputCol, HasOutputCol):\n",
    "    '''\n",
    "    A custom Transformer which applies preprocessing to the text: convert to lowercase and remove punctuation and special characters\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_column, output_column='clean_text'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define inputCol and inputOut\n",
    "        self.inputCol = input_column\n",
    "        self.outputCol = output_column\n",
    "    \n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        # Define text transformation\n",
    "        def lowercase_and_punctuation(text):\n",
    "            lower = text.lower() # lowercase\n",
    "            return re.sub(pattern=r'[^\\w\\s]', repl='', string=lower) # remove all but words, digits and white spaces\n",
    "\n",
    "        udf_preprocess = f.udf(lambda text: lowercase_and_punctuation(text),\n",
    "                               StringType())\n",
    "\n",
    "        # Apply transformation\n",
    "        return df.withColumn(\n",
    "            self.outputCol, udf_preprocess(f.col('overview'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of them, the classes included in PySpark are enough to build a proper Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover\n",
    "\n",
    "# Text preprocessing: convert to lowercase and remove punctuation and special characters\n",
    "preprocessor = TextPreprocessing(input_column='overview', output_column='preprocessed')\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"preprocessed\", outputCol=\"words\")\n",
    "\n",
    "# Remove Stopwords\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "# TF\n",
    "count_vectorizer = CountVectorizer(\n",
    "    inputCol=\"words\", outputCol=\"rawFeatures\", minDF=2, vocabSize=500\n",
    ")\n",
    "\n",
    "hashing_tf = HashingTF(\n",
    "    inputCol='words', outputCol='rawFeatures', numFeatures=500\n",
    ")\n",
    "\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Build a Pipeline with CountVectorizer and another with HashingTF \n",
    "pipeline_CV = Pipeline(stages=[preprocessor, tokenizer, remover, count_vectorizer, idf])\n",
    "pipeline_HTF = Pipeline(stages=[preprocessor, tokenizer, remover, hashing_tf, idf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for both CountVectorizer and HashingTF—in the TF stage definition—some limits were imposed:\n",
    "\n",
    "+ Firstly and more evident, there is a maximum number of features, which is actually much lower than the default size. This is a consequence of having a large number of movies, due to the elevate time it takes to evaluate the similarities of just one movie and the rest. To solve this issue, one option would be to make a previous selection of movies with a lighter method of based on cached information, to then apply the TF-IDF method to a smaller sample.\n",
    "\n",
    "+ Secondly, with CountVectorizer exists the possibility of imposing conditions on the terms to be considered. For this matter, one of the most important one that can be done is requiring a term to appear in more than 1 (or more) documents, because if a term only appears in one document, then the similarity calculation of this element will always be zero—except for when a document is compared with itself. Furthermore, having terms that appear only in a few documents could lead to overfitting.\n",
    "\n",
    "Now, let's continue by building the models to transform the text into vectors and applying them to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features by applying the pipeline, a Hashing technique and the IDF portion\n",
    "model_CV = pipeline_CV.fit(overview)\n",
    "results_CV = model_CV.transform(overview).select('id', 'title', 'overview', 'features')\n",
    "\n",
    "model_HTF = pipeline_HTF.fit(overview)\n",
    "results_HTF = model_HTF.transform(overview).select('id', 'title', 'overview', 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute similarity of a chosen movie with the rest instead of calculating it for every possible combination, as TF-IDF is a costly method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen movie: Pirates of the Caribbean: The Curse of the Black Pearl.\n",
      "Chosen movie: Pirates of the Caribbean: The Curse of the Black Pearl.\n"
     ]
    }
   ],
   "source": [
    "# Create similarity functions\n",
    "example_movie_id = 22\n",
    "\n",
    "udf_similiarity_CV = hf.create_similarity_function(\n",
    "    spark=spark, movie_id=example_movie_id, # <-- Specify movie id to compare\n",
    "    method='cosine', results=results_CV \n",
    ")\n",
    "\n",
    "udf_similiarity_HTF = hf.create_similarity_function(\n",
    "    spark=spark, movie_id=example_movie_id, # <-- Specify movie id to compare\n",
    "    method='cosine', results=results_HTF \n",
    ")\n",
    "\n",
    "# Compute Similarities\n",
    "similarities_CV = results_CV.withColumn(\n",
    "    'similarity', udf_similiarity_CV('features')\n",
    ").\\\n",
    "    select('id', 'title', 'similarity').\\\n",
    "    orderBy('similarity', ascending=False).\\\n",
    "    filter(f.col('id') != example_movie_id)\n",
    "\n",
    "similarities_HTF = results_HTF.withColumn(\n",
    "    'similarity', udf_similiarity_HTF('features')\n",
    ").\\\n",
    "    select('id', 'title', 'similarity').\\\n",
    "    orderBy('similarity', ascending=False).\\\n",
    "    filter(f.col('id') != example_movie_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CountVectorizer Method ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>966</td>\n",
       "      <td>The Magnificent Seven</td>\n",
       "      <td>0.432751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149218</td>\n",
       "      <td>Come Dance with Me</td>\n",
       "      <td>0.429970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206183</td>\n",
       "      <td>Bad Karma</td>\n",
       "      <td>0.421883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                  title  similarity\n",
       "0     966  The Magnificent Seven    0.432751\n",
       "1  149218     Come Dance with Me    0.429970\n",
       "2  206183              Bad Karma    0.421883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 85.0 seconds.\n",
      "\n",
      "\n",
      "--- HashingTF Method ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353069</td>\n",
       "      <td>Mother's Day</td>\n",
       "      <td>0.384116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157129</td>\n",
       "      <td>Table No. 21</td>\n",
       "      <td>0.361648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37602</td>\n",
       "      <td>Oysters at Nam Kee's</td>\n",
       "      <td>0.350613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                 title  similarity\n",
       "0  353069          Mother's Day    0.384116\n",
       "1  157129          Table No. 21    0.361648\n",
       "2   37602  Oysters at Nam Kee's    0.350613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 100.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Show similarity values\n",
    "start = time.time()\n",
    "print('--- CountVectorizer Method ---')\n",
    "display(similarities_CV.limit(3).toPandas())\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {np.round(end-start)} seconds.\\n\\n')\n",
    "\n",
    "start = time.time()\n",
    "print('--- HashingTF Method ---')\n",
    "display(similarities_HTF.limit(3).toPandas())\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {np.round(end-start)} seconds.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results were similar in time and in value spread, although for *HashingTF* the first recommendation is slightly clearer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there is an alternative method for similarity calculation which involves LSH, an approximated method that only considers the closest neighbours. The function to use is the following one:\n",
    "\n",
    "```\n",
    "BucketedRandomProjectionLSH(\n",
    "    inputCol, outputCol, bucketLength, numHashTables\n",
    ")\n",
    "```\n",
    "+ *inputCol* and *outputCol* are the same as other PySpark functions (i.e. are used to indicate which column to take the data from and the column to dump the output).\n",
    "\n",
    "+ *bucketLength*: LSH creates group together hashes into the same bucket. The width of said buckets depends on this parameter, so the smaller it is, the more precision, due to the separation of hashes into different buckets. In other words, the greater this parameter, the greater the dimensionality reduction.\n",
    "\n",
    "+ *numHashTables*: In LSH, instead of relying on a single hash function, multiple ones are used to increase the chance that similar points are hashed in the same bucket. However, this also tends to introduce false positives.\n",
    "\n",
    "To choose these parameters, there are several guidelines:\n",
    "\n",
    "+ If the features are normalized *bucketLength* should be around 1 to 10, but if there is high variability, opt for 1% to 10% of the standard deviation of the data—although this requires calculating pairwise distances.\n",
    "\n",
    "+ For most applications, starting with a *numHashTables* from 10 to 25 is reasonable, but for high dimensionality data the numbers could go up around 30 to 50 hash tables.\n",
    "\n",
    "+ Finally, if the results seem irrelevant (too many false positive), either increase *bucketLength* or reduce *numHashTables*. Ans if the results are missing important matches (too many false negatives), decrease *bucketLength* or increase *nuHashTables*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSH Method ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy Ever Afters</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mother's Day</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enola Gay and the Atomic Bombing of Japan</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tour de Pharmacy</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  similarity\n",
       "0                          Happy Ever Afters       0.043\n",
       "1                               Mother's Day       0.042\n",
       "2  Enola Gay and the Atomic Bombing of Japan       0.042\n",
       "3                           Tour de Pharmacy       0.041\n",
       "4                                    Iceland       0.041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 24.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Hash words with HashingTF (with expanded vocabulary)\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "\n",
    "hashing_tf = HashingTF(\n",
    "    inputCol='words', outputCol='rawFeatures', numFeatures=1500 # <--- more words!\n",
    ")\n",
    "\n",
    "pipeline_HTF = Pipeline(stages=[preprocessor, tokenizer, remover,\n",
    "                                hashing_tf, idf])\n",
    "\n",
    "results_HTF = pipeline_HTF.fit(overview).transform(overview).\\\n",
    "    select('id', 'title', 'overview', 'features')\n",
    "\n",
    "# Apply LSH (Bucketed Random Projection LSH)\n",
    "lsh = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", \n",
    "                                  bucketLength=1, numHashTables=25)\n",
    "lsh_model = lsh.fit(results_HTF)\n",
    "\n",
    "# Find similar items for the example movie\n",
    "similar_items = lsh_model.approxNearestNeighbors(\n",
    "    results_HTF.filter(f.col('id') != example_movie_id),\n",
    "    results_HTF.filter(f.col('id') == example_movie_id).select('features').collect()[0][0],\n",
    "    numNearestNeighbors=5\n",
    ")\n",
    "\n",
    "# Show results\n",
    "def similarity_from_distance(distance):\n",
    "    return float(round(1 / (distance+1), 3))\n",
    "udf_similarity_from_distance = f.udf(lambda d: similarity_from_distance(d),\n",
    "                                     FloatType())\n",
    "\n",
    "start = time.time()\n",
    "print('--- LSH Method ---')\n",
    "\n",
    "display(similar_items.select(\"title\", \"distCol\").\\\n",
    "        withColumn('similarity', udf_similarity_from_distance(f.col('distCol'))).\\\n",
    "        select('title', 'similarity').\\\n",
    "            limit(5).toPandas())\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {np.round(end-start)} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec and LSH\n",
    ">A model with a Neural Network architecture capable of grouping in the embedding vector space synonyms and words with similar semantic function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec computes distributed vector representation of the words of the corpus. To do that, the context of the word is taking into account—i.e. the surrounding words—, so that terms with similar meaning (synonyms) or with similar semantic function are assigned vectors close to each other. This improves the model generalization and makes it more robust.\n",
    "\n",
    "At a technical level, Word2Vec is a two-layer neural network that processes batches of text and returns a vector for each unique word. This vector will belong to a vector space usually of several hundred dimensions.\n",
    "\n",
    "The Word2Vec model can use either of two architectures: Continuous Bag of Words (CBOW) or Continuous Skip-Gram. Both models aim to reduce dimensionality and produce dense vector representations of words (embeddings) from a large corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### CBOW: Continuous Bag of Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "According to *Wikipedia*, the CBOW model can be viewed as a \"fill the blank\" task. The reason for this is that the model is trained by predicting what word was removed from a batch of text based on the surrounding words, under the assumption that the order does not influence the prediction (bag of words). \n",
    "\n",
    "For example, if in the sentence \"the cat on the mat\" the target word is \"cat\", then the model will give a prediction for the set of words [\"the\", \"on\", \"the\", \"mat\"], which turns into [\"the\", \"on\", \"mat\"] due to the bag of words assumption. Based on the similarity of the prediction compared to \"cat\" the weights of the model will change, and the mentioned prediction is obtained assuming that the missing word must be similar to the average embedding of the surrounding words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Continuous Skip-Gram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "According to *Wikipedia*, the Skip-Gram model can be viewed as a \"find the neighbors\" task, so in a way is the opposite problem of CBOW. The reason for this is that the model is trained by predicting the context surrounding the target word. This makes the Slip-Gram model versatile with rare words, as it improves its ability to capture semantic relationships and flexibility to linguistic context, but it requires higher computation effort to train than CBOW.\n",
    "\n",
    "Let's focus on the mathematical view of the problem:\n",
    "+ Sequence of training words: $w_1,\\dots,w_T$.\n",
    "\n",
    "+ Objective: maximize the average log-likelihood: $$\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{j=-k}^{+k} \\log p(w_{t+j}|w_t),$$ where $k$ is the size of the training window. For example: $$w_1,\\dots,w_{t-2},[w_{t-1},w_{t},w_{t+1}],w_{t+2},\\dots,w_T,$$ where the brackets mark the window of $k=1$ around the target word, $w_t$.\n",
    "\n",
    "+ Definitions:\n",
    "    + $u_w$: vector representation of $w$ as a word.\n",
    "\n",
    "    + $v_w$: vector representation of $w$ as context for another word.\n",
    "\n",
    "    + From softmax: $p(w_i|w_j) = \\frac{exp\\left( u_{w_{i}}^T\\cdot v_{w_j} \\right)}{\\sum_{l=1}^{V} exp\\left( u_l^T\\cdot v_{w_j} \\right)},$ where $V$ is the vocabulary size.\n",
    "\n",
    "From these definitions, the objective is to maximize:\n",
    "$$\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{j=-k}^{+k} \\left( u_{w_{i}}^T\\cdot v_{w_j} - \\log\\left[ \\sum_{l=1}^{V} exp\\left( u_l^T\\cdot v_{w_j} \\right) \\right] \\right).$$\n",
    "\n",
    "However, the last portion of the equation—the logarithm of the sum of all vocabulary—is expensive, because the size of the vocabulary, $V$, can be in the order of millions. For this reason, in many cases—one of them the PySpark function—, instead hierarchical softmax is used, which reduces the cost to $O(\\log(v))$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of *Word2Vec* in *PySpark*  only includes **Skip-Gram**, not CBOW. This means that the model's architecture is designed to learn word vector representations that are good at predicting its context in the same sentence.\n",
    "\n",
    "Let's start understanding the parameters of the *Word2Vec* function call:\n",
    "\n",
    "    Word2Vec(inputCol, outputCol, seed, numPartitions,  vectorSize, ...)\n",
    "\n",
    "+ The parameters *inputCol* and *outputCol* serve to identify the column to feed the model (input), and the column to dump the results (output).\n",
    "\n",
    "+ *seed*: random value used to set the initial weights of the neural network.\n",
    "\n",
    "+ *numPartitions*: defaults to 1, meaning that training the *Word2Vec* model would happen at a single executor. Increasing it will introduce parallelization, making the training faster, but there are two things to have into account:\n",
    "    \n",
    "    1. **Risk of overheat**: Splitting, managing and merging partitions takes \"extra effort\" (overheat), and it increases the more partitions are assigned.\n",
    "\n",
    "    2. **Decrease in model accuracy**: due to data partition, each of the executors will train a *Word2Vec* model on a portion of the data before merging them together. To counter this to a certain extent, the optional input parameter *maxIter* is very useful, because in each iteration the data is shuffled, allowing the executor to access he rest of the data. The number can range between $\\text{\\textit{numPartition}}/5$ for large datasets and $\\text{\\textit{numPartition}} - 1$ for smaller ones.\n",
    "\n",
    "+ **vectorSize**: the length of the embedding assigned to every term in the vocabulary. Its value affects the computational cost directly, but the larger it is, the more meaning that can be captured. However, overfitting is also an issue, thus for smaller datasets a value between 50 and 100 is a great starting point, while for larger data sets the values range between 200 and 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text input will come from the movies overview, like for the TF-IDF model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Shadows in Paradise</td>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                title                                           overview\n",
       "0   2                Ariel  Taisto Kasurinen is a Finnish coal miner whose...\n",
       "1   3  Shadows in Paradise  An episode in the life of Nikander, a garbage ...\n",
       "2   5           Four Rooms  It's Ted the Bellhop's first night on the job...."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overview = df.select('id', 'title', 'overview').orderBy('id').na.drop(subset=[\"overview\"])\n",
    "display(overview.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Shadows in Paradise</td>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                title                                           overview\n",
       "0   2                Ariel  Taisto Kasurinen is a Finnish coal miner whose...\n",
       "1   3  Shadows in Paradise  An episode in the life of Nikander, a garbage ...\n",
       "2   5           Four Rooms  It's Ted the Bellhop's first night on the job...."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import FloatType, StringType, ArrayType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Original data\n",
    "original_sample = overview.limit(3).toPandas()\n",
    "display(original_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the TF-IDF section, the data preparation was handled using a Pipeline. However, in this case, the process is itemized to provide an alternative approach. Additionally, a new stage called **\"Stemming\"** is introduced, which removes suffixes of words to heuristically form their root. This process is often linguistically incorrect, but it is less costly than other exhaustive techniques like \"Lemmatization\". For example, stemming could produce the following results:\n",
    "\n",
    "+ \"involved\" → \"involv\" (linguistically correct).\n",
    "\n",
    "+ \"running\" → \"runn\" (linguistically incorrect, lemmatization would return \"run\").\n",
    "\n",
    "+ \"flies\" → \"fli\" (linguistically incorrect, lemmatization would return \"fly\").\n",
    "\n",
    "Let's start the text preprocessing by transforming the words into lowercase, so that the model doesn't treat differently, for example, \"Houses\" and \"houses\". Nevertheless, this is a choice made to reduce vocabulary size, and it could be reasonable to distinguish between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "      <td>taisto kasurinen is a finnish coal miner whose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "      <td>an episode in the life of nikander, a garbage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "      <td>it's ted the bellhop's first night on the job....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0  Taisto Kasurinen is a Finnish coal miner whose...   \n",
       "1  An episode in the life of Nikander, a garbage ...   \n",
       "2  It's Ted the Bellhop's first night on the job....   \n",
       "\n",
       "                                               lower  \n",
       "0  taisto kasurinen is a finnish coal miner whose...  \n",
       "1  an episode in the life of nikander, a garbage ...  \n",
       "2  it's ted the bellhop's first night on the job....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lowercase\n",
    "def lowercase(df: DataFrame, inputCol: str, outputCol: str = 'lower'):\n",
    "    return df.withColumn(outputCol, f.lower(f.col(inputCol)))\n",
    "\n",
    "cleaned = lowercase(overview, 'overview')\n",
    "display(cleaned.limit(3).select('overview', 'lower').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to remove special character. This is done with regular expressions, thus there is freedom to skip some specific symbols. In the TF-IDF section, the pattern to be removed was \"[^\\w\\s]\", which means all but alphanumeric symbols (\\w) and white-spaces (\\s). It is reasonable to use the same one for Word2Vec, but to avoid affecting words like \"It's\", let's use in this case the pattern \"[^\\w\\s\\\\']\" to skip apostrophes as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>no_special_characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "      <td>taisto kasurinen is a finnish coal miner whose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "      <td>an episode in the life of nikander a garbage m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "      <td>it's ted the bellhop's first night on the joba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0  Taisto Kasurinen is a Finnish coal miner whose...   \n",
       "1  An episode in the life of Nikander, a garbage ...   \n",
       "2  It's Ted the Bellhop's first night on the job....   \n",
       "\n",
       "                               no_special_characters  \n",
       "0  taisto kasurinen is a finnish coal miner whose...  \n",
       "1  an episode in the life of nikander a garbage m...  \n",
       "2  it's ted the bellhop's first night on the joba...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove Special Characters\n",
    "def filter_special_characters(df: DataFrame, inputCol: str, outputCol: str = 'no_special_characters'):\n",
    "    return df.withColumn(\n",
    "        outputCol,\n",
    "        f.regexp_replace(\n",
    "            string=f.col(inputCol), pattern=r\"[^\\w\\s\\']\", replacement=''\n",
    "        )\n",
    "    )\n",
    "\n",
    "cleaned = filter_special_characters(cleaned, 'lower')\n",
    "display(cleaned.limit(3).select('overview', 'no_special_characters').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, tokenization will split the sentences into lists of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "      <td>[taisto, kasurinen, is, a, finnish, coal, mine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "      <td>[an, episode, in, the, life, of, nikander, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "      <td>[it's, ted, the, bellhop's, first, night, on, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0  Taisto Kasurinen is a Finnish coal miner whose...   \n",
       "1  An episode in the life of Nikander, a garbage ...   \n",
       "2  It's Ted the Bellhop's first night on the job....   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [taisto, kasurinen, is, a, finnish, coal, mine...  \n",
       "1  [an, episode, in, the, life, of, nikander, a, ...  \n",
       "2  [it's, ted, the, bellhop's, first, night, on, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenization\n",
    "def tokenization(df: DataFrame, inputCol: str, outputCol: str = 'tokenized'):\n",
    "    tokenizer = Tokenizer(inputCol=inputCol, outputCol=outputCol) # Initialize\n",
    "    return tokenizer.transform(df) # Transform\n",
    "\n",
    "cleaned = tokenization(cleaned, 'no_special_characters')\n",
    "display(cleaned.limit(3).select('overview', 'tokenized').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tokenization, it is possible to remove stopwords from the vocabulary, because they appear in most of the documents, making them have low impact on understanding the meaning of the sentence. However, it is reasonable to keep them if the dataset is small—to lose as little information as possible—and for some specific cases, such as sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "      <td>[taisto, kasurinen, finnish, coal, miner, whos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "      <td>[episode, life, nikander, garbage, man, involv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "      <td>[ted, bellhop's, first, night, joband, hotel's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0  Taisto Kasurinen is a Finnish coal miner whose...   \n",
       "1  An episode in the life of Nikander, a garbage ...   \n",
       "2  It's Ted the Bellhop's first night on the job....   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  [taisto, kasurinen, finnish, coal, miner, whos...  \n",
       "1  [episode, life, nikander, garbage, man, involv...  \n",
       "2  [ted, bellhop's, first, night, joband, hotel's...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove StopWords\n",
    "def remove_stopwords(df: DataFrame, inputCol: str, outputCol: str = 'no_stopwords'):\n",
    "    remover = StopWordsRemover(inputCol=inputCol, outputCol=outputCol) # initialize\n",
    "    return remover.transform(cleaned) # transform\n",
    "\n",
    "cleaned = remove_stopwords(cleaned, 'tokenized')\n",
    "display(cleaned.limit(3).select('overview', 'no_stopwords').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the new stage, Stemming. In this case, PySpark does not have an implementation for this kind of preprocessing, but the library *nltk* has a Stemmer that can be used with PySpark's udf to transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "      <td>[taisto, kasurinen, finnish, coal, miner, whos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "      <td>[episod, life, nikand, garbag, man, involv, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "      <td>[ted, bellhop, first, night, joband, hotel, un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0  Taisto Kasurinen is a Finnish coal miner whose...   \n",
       "1  An episode in the life of Nikander, a garbage ...   \n",
       "2  It's Ted the Bellhop's first night on the job....   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [taisto, kasurinen, finnish, coal, miner, whos...  \n",
       "1  [episod, life, nikand, garbag, man, involv, de...  \n",
       "2  [ted, bellhop, first, night, joband, hotel, un...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stemming\n",
    "def stem(df: DataFrame, inputCol: str, outputCol: str = 'stemmed'):\n",
    "  stemmer = SnowballStemmer(language='english') # initialize\n",
    "  \n",
    "  # The stemmer has to be applied to every word of the list and each row \n",
    "  # has a list of words\n",
    "  udf_stemmer = f.udf(\n",
    "    lambda term_list: [stemmer.stem(term) for term in term_list], \n",
    "    ArrayType(StringType()))\n",
    "\n",
    "  # Apply to dataframe\n",
    "  return df.withColumn(outputCol, udf_stemmer(inputCol))\n",
    "\n",
    "cleaned = stem(cleaned, 'no_stopwords')\n",
    "display(cleaned.limit(3).select('overview', 'stemmed').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: make sure that there is no column named like *outputCol* in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "      <td>[-0.08147076639113948, 0.09922557100653649, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "      <td>[-0.06687724217772484, 0.09172882363200188, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "      <td>[-0.05516240233555436, 0.10162156131118537, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0  Taisto Kasurinen is a Finnish coal miner whose...   \n",
       "1  An episode in the life of Nikander, a garbage ...   \n",
       "2  It's Ted the Bellhop's first night on the job....   \n",
       "\n",
       "                                            features  \n",
       "0  [-0.08147076639113948, 0.09922557100653649, 0....  \n",
       "1  [-0.06687724217772484, 0.09172882363200188, 0....  \n",
       "2  [-0.05516240233555436, 0.10162156131118537, -0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "def embedding_W2V(df: DataFrame, inputCol: str, outputCol: str = 'features'):\n",
    "    # Initialize\n",
    "    word2vec = Word2Vec(inputCol=inputCol, outputCol=outputCol,\n",
    "                        seed=33, vectorSize=50,\n",
    "                        numPartitions=11, minCount=10)\n",
    "\n",
    "    # Learn vocabulary and learn the weights\n",
    "    model = word2vec.fit(cleaned)\n",
    "\n",
    "    # Embeddings\n",
    "    return model.transform(df)\n",
    "\n",
    "cleaned = embedding_W2V(cleaned, 'stemmed')\n",
    "display(cleaned.limit(3).select('overview', 'features').toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSH Method ---\n",
      "Movies similar to Pirates of the Caribbean: The Curse of the Black Pearl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Adventures of Tarzan</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ten Tall Men</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  similarity\n",
       "0  The Adventures of Tarzan       0.828\n",
       "1              Ten Tall Men       0.824\n",
       "2                    Alaska       0.823"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 29.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "import time\n",
    "\n",
    "# Apply LSH (Bucketed Random Projection LSH)\n",
    "lsh = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", \n",
    "                                  bucketLength=1, numHashTables=25)\n",
    "lsh_model = lsh.fit(cleaned)\n",
    "\n",
    "# Find items similar to the example movie\n",
    "example_movie_id = 22 # <-- Arbitrary id\n",
    "similar_items = lsh_model.approxNearestNeighbors(\n",
    "    cleaned.filter(f.col('id') != example_movie_id),\n",
    "    cleaned.filter(f.col('id') == example_movie_id).select('features').collect()[0][0],\n",
    "    numNearestNeighbors=5\n",
    ")\n",
    "\n",
    "# Start timer and print reference movie\n",
    "start = time.time()\n",
    "print('--- LSH Method ---\\n' +\n",
    "      f'Movies similar to {cleaned.filter(f.col(\"id\") == example_movie_id).select(\"title\").collect()[0][0]}.')\n",
    "\n",
    "# Custom similarity from distance metric\n",
    "udf_similarity_from_distance = f.udf(lambda d: float(round(1 / (d+1), 3)),\n",
    "                                     FloatType())\n",
    "\n",
    "# Queue similarity transformation\n",
    "results = similar_items.select(\"title\", \"distCol\").\\\n",
    "    withColumn('similarity', udf_similarity_from_distance(f.col('distCol'))).\\\n",
    "        select('title', 'similarity')\n",
    "\n",
    "# Compute similarity\n",
    "display(results.limit(3).select('title', 'similarity').toPandas())\n",
    "\n",
    "# Stop timer and show time elapsed\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {np.round(end-start)} seconds.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition (SVD)\n",
    ">A dimensionality reduction technique to increase efficiency in similarity calculations. Works best for medium and small datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Singular Value Decomposition or SVD is a technique that decomposes a matrix into three. For instance, let's say a matrix $\\underline{\\underline{A}}$ is storing information about movies like this:\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "\n",
    "|             | **Feature 1** | **Feature 2** | **Feature 3** |\n",
    "|:-----------:|:-------------:|:-------------:|:-------------:|\n",
    "| **Movie 1** |      0.3      |      0.1      |      0.0      |\n",
    "| **Movie 2** |      0.5      |      0.0      |      0.8      |\n",
    "\n",
    "Table 1: Example of a movie-feature matrix.\n",
    "\n",
    "</center>\n",
    "<br />\n",
    "\n",
    "Where 'Features' refer to any way to identify a movie. Let's be more specific and work with movie genres, although the values will be arbitrary:\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "\n",
    "|             | **Space** | **Time** | **Travel** | **Alien** | **Love** |\n",
    "|:-----------:|:---------:|:--------:|:----------:|:---------:|:--------:|\n",
    "| **Movie 1** |     1     |     1    |      1     |     0     |     0    |\n",
    "| **Movie 2** |     0     |     0    |      1     |     0     |     1    |\n",
    "\n",
    "Table 2: A more specific example of a movie-feature matrix using genres as features.\n",
    "\n",
    "</center>\n",
    "<br />\n",
    "\n",
    "Now that the matrix $\\underline{\\underline{A}}$ is defined, the basic idea of SVD is that instead of representing the movies with these 5 genres—which in turn is a five dimensional space—, they will be represented in fewer, yet more general 'Topics'. These 'Topics' could relate to the original genres as follows:\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "\n",
    "|                      | **Space** | **Time** | **Travel** | **Alien** | **Love** |\n",
    "|:--------------------:|:---------:|:--------:|:----------:|:---------:|:--------:|\n",
    "|  **Topic 1: Sci-Fi** |    0.7    |    0.6   |     0.8    |    0.5    |    0.0   |\n",
    "| **Topic 2: Romance** |    0.0    |    0.1   |     0.5    |    0.3    |    0.9   |\n",
    "\n",
    "Table 3: Representation of Features in the new space.\n",
    "\n",
    "</center>\n",
    "<br />\n",
    "\n",
    "And consequently, allow this new representation:\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "\n",
    "|             | **Topic 1: Sci-Fi** | **Topic 2: Romance** |\n",
    "|:-----------:|:-------------------:|:--------------------:|\n",
    "| **Movie 1** |         0.9         |          0.1         |\n",
    "| **Movie 2** |         0.2         |          0.8         |\n",
    "\n",
    "Table 4: Representation of Movies in the new space.\n",
    "\n",
    "</center>\n",
    "<br />\n",
    "\n",
    "In summary, with SVD it is possible to reduce the dimensionality of the problem at hand, making it less computationally intensive, and thus making the similarity calculation faster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### SVD with a more mathematical approach\n",
    "\n",
    "Let's say that our matrix $\\underline{\\underline{A}}$ (movies as rows and features as columns) is a $n\\times m$ matrix, meaning that it is representing $n$ movies with $m$ features. To describe the movies in a different way—with more general features, as with the 'Topics' before—, $\\underline{\\underline{A}}$ will be factorized in its *latent factors*.\n",
    "\n",
    "The maximum number of latent factors is determined by $\\underline{\\underline{A}}$ and can be extracted from its *rank*:\n",
    "\n",
    "$$k \\equiv \\text{rank}(\\underline{\\underline{A}}_{n\\times m}) \\leq \\min(n,m).$$\n",
    "\n",
    "So the factorization of a matrix $\\underline{\\underline{A}}_{n\\times m}$ and rank $k$ in its latent factors would be as follows:\n",
    "\n",
    "$$\\underline{\\underline{A}}_{n\\times m} = \\underline{\\underline{U}}_{n\\times k}\\; \\underline{\\underline{\\Sigma}}_{k\\times k}\\; \\underline{\\underline{V}}_{k\\times m}^T,$$\n",
    "\n",
    "where:\n",
    "\n",
    "+ $\\underline{\\underline{U}}_{n\\times k}$ is the representation of the movies in the new space, i.e. Table 4.\n",
    "\n",
    "+ $\\underline{\\underline{\\Sigma}}_{k\\times k}$ is a diagonal matrix that contains the *singular values* of the original matrix, which indicate the importance of each latent factor.\n",
    "\n",
    "+ $\\underline{\\underline{V}}_{k\\times m}^T$ represents the features in the new space, i.e. Table 3.\n",
    "\n",
    "Finally, using the singular values from the matrix $\\underline{\\underline{\\Sigma}}$ it is possible to determine which latent values are more important to the current data. This opens the possibility of truncation, meaning that there is no need to keep all $k$ latent factors, but only the most important ones to represent the data more efficiently, if only sacrificing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68720</td>\n",
       "      <td>Tammy and the Doctor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72074</td>\n",
       "      <td>Murderer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>288154</td>\n",
       "      <td>Jersey Shore Massacre</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                  title  Action  Adventure  Animation  Comedy  Crime  \\\n",
       "0   68720   Tammy and the Doctor       0          0          0       1      0   \n",
       "1   72074               Murderer       0          0          0       0      1   \n",
       "2  288154  Jersey Shore Massacre       0          0          0       1      0   \n",
       "\n",
       "   Documentary  Drama  Family  ...  History  Horror  Music  Mystery  Romance  \\\n",
       "0            0      0       0  ...        0       0      0        0        1   \n",
       "1            0      1       0  ...        0       0      0        1        0   \n",
       "2            0      0       0  ...        0       1      0        0        0   \n",
       "\n",
       "   Science Fiction  TV Movie  Thriller  War  Western  \n",
       "0                0         0         0    0        0  \n",
       "1                0         0         1    0        0  \n",
       "2                0         0         0    0        0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import time\n",
    "\n",
    "# Create Movie-Genres dataframe\n",
    "genres = df.select('id', 'title',\n",
    "                   f.explode(f.col('genres')).alias('genre'), # A row per genre\n",
    "                   f.lit(1).alias('value')) # Mark as present\n",
    "\n",
    "genres = genres.groupby('id', 'title').pivot('genre').sum('value').fillna(0)\n",
    "display(genres.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68720</td>\n",
       "      <td>Tammy and the Doctor</td>\n",
       "      <td>[-0.37249461810173123, -0.9533260450342833, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72074</td>\n",
       "      <td>Murderer</td>\n",
       "      <td>[1.1079085340316965, 0.36656159395470356, -1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>288154</td>\n",
       "      <td>Jersey Shore Massacre</td>\n",
       "      <td>[-0.5493537603056138, -0.37159302194402466, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                  title  \\\n",
       "0   68720   Tammy and the Doctor   \n",
       "1   72074               Murderer   \n",
       "2  288154  Jersey Shore Massacre   \n",
       "\n",
       "                                            features  \n",
       "0  [-0.37249461810173123, -0.9533260450342833, -0...  \n",
       "1  [1.1079085340316965, 0.36656159395470356, -1.0...  \n",
       "2  [-0.5493537603056138, -0.37159302194402466, -0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert Genre Columns to Feature Vector\n",
    "vector_assembler = VectorAssembler(inputCols=genres.drop('title', 'id').columns, outputCol=\"genres_features\")\n",
    "df_features = vector_assembler.transform(genres).select('id', \"title\", \"genres_features\")\n",
    "\n",
    "# Apply SVD (using PCA as a substitute for Truncated SVD)\n",
    "k = 5  # Reduce to 5 latent dimensions\n",
    "pca = PCA(k=k, inputCol=\"genres_features\", outputCol=\"features\")\n",
    "df_svd = pca.fit(df_features).transform(df_features).select('id', \"title\", \"features\")\n",
    "\n",
    "display(df_svd.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen movie: Pirates of the Caribbean: The Curse of the Black Pearl.\n",
      "--- SVD Method ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>558</td>\n",
       "      <td>Spider-Man 2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84633</td>\n",
       "      <td>Quest of the Delta Knights</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297762</td>\n",
       "      <td>Wonder Woman</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37430</td>\n",
       "      <td>Conan the Barbarian</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>347096</td>\n",
       "      <td>Mythica: The Darkspore</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23047</td>\n",
       "      <td>Season of the Witch</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>121</td>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8009</td>\n",
       "      <td>Highlander</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32654</td>\n",
       "      <td>The Storm Warriors</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9387</td>\n",
       "      <td>Conan the Barbarian</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                  title  similarity\n",
       "0     558                           Spider-Man 2         1.0\n",
       "1   84633             Quest of the Delta Knights         1.0\n",
       "2  297762                           Wonder Woman         1.0\n",
       "3   37430                    Conan the Barbarian         1.0\n",
       "4  347096                 Mythica: The Darkspore         1.0\n",
       "5   23047                    Season of the Witch         1.0\n",
       "6     121  The Lord of the Rings: The Two Towers         1.0\n",
       "7    8009                             Highlander         1.0\n",
       "8   32654                     The Storm Warriors         1.0\n",
       "9    9387                    Conan the Barbarian         1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 3.0 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create similarity functions\n",
    "example_movie_id = 22\n",
    "\n",
    "udf_similiarity = hf.create_similarity_function(\n",
    "    spark=spark, movie_id=example_movie_id, \n",
    "    method='cosine', results=df_svd # <-- Specify movie id to compare\n",
    ")\n",
    "\n",
    "# Compute Similarities\n",
    "similarities = df_svd.withColumn(\n",
    "    'similarity', udf_similiarity('features')\n",
    ").\\\n",
    "    select('id', 'title', 'similarity').\\\n",
    "    orderBy('similarity', ascending=False).\\\n",
    "    filter(f.col('id') != example_movie_id)\n",
    "\n",
    "# Show similarity values\n",
    "start = time.time()\n",
    "print('--- SVD Method ---')\n",
    "display(similarities.limit(10).toPandas())\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {np.round(end-start)} seconds.\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a simple recommender system by movie genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Straight Outta Compton</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Straight Outta Compton</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Viva Algeria</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title  genre\n",
       "0  Straight Outta Compton  Drama\n",
       "1  Straight Outta Compton  Music\n",
       "2            Viva Algeria  Drama"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explode genre list into different columns\n",
    "genres = df.select('genres', 'title')\n",
    "genres = df.select(df.title, f.explode(df.genres).alias('genre'))\n",
    "display(genres.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Straight Outta Compton</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Straight Outta Compton</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Viva Algeria</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title  genre  value\n",
       "0  Straight Outta Compton  Drama      1\n",
       "1  Straight Outta Compton  Music      1\n",
       "2            Viva Algeria  Drama      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a columns of 1 to indicate a movies has a specific genre\n",
    "genres = genres.withColumn('value', f.lit(1))\n",
    "display(genres.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All The Days Before Tomorrow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snowman's Land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  Action  Adventure  Animation  Comedy  Crime  \\\n",
       "0                   We Are Many     NaN        NaN        NaN     NaN    NaN   \n",
       "1  All The Days Before Tomorrow     NaN        NaN        NaN     1.0    NaN   \n",
       "2                Snowman's Land     NaN        NaN        NaN     1.0    1.0   \n",
       "\n",
       "   Documentary  Drama  Family  Fantasy  ...  History  Horror  Music  Mystery  \\\n",
       "0          1.0    NaN     NaN      NaN  ...      NaN     NaN    NaN      NaN   \n",
       "1          NaN    1.0     NaN      NaN  ...      NaN     NaN    NaN      NaN   \n",
       "2          NaN    NaN     NaN      NaN  ...      NaN     NaN    NaN      NaN   \n",
       "\n",
       "   Romance  Science Fiction  TV Movie  Thriller  War  Western  \n",
       "0      NaN              NaN       NaN       NaN  NaN      NaN  \n",
       "1      1.0              NaN       NaN       NaN  NaN      NaN  \n",
       "2      NaN              NaN       NaN       1.0  NaN      NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set movies as rows (groupby) and genres as columns (pivot)\n",
    "# sum() makes sure it is one on the (title, genre) pairs indicated above\n",
    "genres = genres.groupby('title').pivot('genre').sum('value')\n",
    "display(genres.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All The Days Before Tomorrow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snowman's Land</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  Action  Adventure  Animation  Comedy  Crime  \\\n",
       "0                   We Are Many       0          0          0       0      0   \n",
       "1  All The Days Before Tomorrow       0          0          0       1      0   \n",
       "2                Snowman's Land       0          0          0       1      1   \n",
       "\n",
       "   Documentary  Drama  Family  Fantasy  ...  History  Horror  Music  Mystery  \\\n",
       "0            1      0       0        0  ...        0       0      0        0   \n",
       "1            0      1       0        0  ...        0       0      0        0   \n",
       "2            0      0       0        0  ...        0       0      0        0   \n",
       "\n",
       "   Romance  Science Fiction  TV Movie  Thriller  War  Western  \n",
       "0        0                0         0         0    0        0  \n",
       "1        1                0         0         0    0        0  \n",
       "2        0                0         0         1    0        0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finally, set the NULLs as 0, which indicate that the movie hasn't that genre\n",
    "genres = genres.fillna(0)\n",
    "display(genres.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame stores the movie-genre relationships, which are required to calculate the similarities. In this scenario, it is a good idea to preemptively calculate similarities and cache them, so the recommendations can happen in real time. To do this, the first step is to turn the movies into vectors, which is an easy task considering the rows of the movie-genre DataFrame is a vector representation of the movies in the genre space. However, to save up memory, it is wise to use dense vectors, because most of the values are zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------+\n",
      "|title                       |features                   |\n",
      "+----------------------------+---------------------------+\n",
      "|We Are Many                 |(20,[5],[1.0])             |\n",
      "|All The Days Before Tomorrow|(20,[3,6,14],[1.0,1.0,1.0])|\n",
      "|Snowman's Land              |(20,[3,4,17],[1.0,1.0,1.0])|\n",
      "+----------------------------+---------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# Train vector assembler on the dataframe\n",
    "vector_assembler = VectorAssembler(inputCols=genres.columns[1:],\n",
    "                                   outputCol='features')\n",
    "\n",
    "# Create the column features with the Dense Vector representation\n",
    "movie_features = vector_assembler.transform(genres).select('title', 'features')\n",
    "movie_features.show(3, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although in pandas, dense vectors show like usual vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All The Days Before Tomorrow</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snowman's Land</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0                   We Are Many   \n",
       "1  All The Days Before Tomorrow   \n",
       "2                Snowman's Land   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(movie_features.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to calculate the similarities for each pair of movies, let's join the resulting DataFrame with itself. This will result into a DataFrame whose rows will contain two movies—thus, two dense vectors. However, there are two things that must be guaranteed:\n",
    "\n",
    "+ For every row, the two movies cannot be the same. This would lead to the calculation of the similarity between them, which will not do any good to the recommender system.\n",
    "\n",
    "+ The pair (A,B) yields the same similarity than the pair (B,A), so there is no need to calculate them both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>All The Days Before Tomorrow</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>Snowman's Land</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                           features  \\\n",
       "0  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "2  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                          title  \\\n",
       "0                   We Are Many   \n",
       "1  All The Days Before Tomorrow   \n",
       "2                Snowman's Land   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cross Join: Cartesian Product of the tables\n",
    "df_cross = movie_features.alias('left').crossJoin(movie_features.alias('right'))\n",
    "display(df_cross.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter out the rows with the same movie twice and the repeated pairs, Python allows the use of '<' to compare text. For example:\n",
    "\n",
    "+ 'The Hunger Games' < 'Braveheart' = False.\n",
    "\n",
    "+ 'Braveheart' < 'The Hunger Games' = True.\n",
    "\n",
    "Because 'B' comes before 'T', due to the alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>What No One Knows</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>What Have They Done to Your Daughters?</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>We are the tide</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                           features  \\\n",
       "0  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "2  We Are Many  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                    title  \\\n",
       "0                       What No One Knows   \n",
       "1  What Have They Done to Your Daughters?   \n",
       "2                         We are the tide   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cross = df_cross.filter(f.col('left.title') < f.col('right.title'))\n",
    "display(df_cross.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the similarities will be stored in a new column and calculated via User Defined Functions (udf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>What No One Knows</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>What Have They Done to Your Daughters?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>We are the tide</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Window Water Baby Moving</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Wood Job!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Zodiac: The Race Begins...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Убить дракона</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Women of the Night</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>Wise Guys</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We Are Many</td>\n",
       "      <td>You Wont Miss Me</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                   title  jaccard  cosine\n",
       "0  We Are Many                       What No One Knows      0.0     0.0\n",
       "1  We Are Many  What Have They Done to Your Daughters?      0.0     0.0\n",
       "2  We Are Many                         We are the tide      0.0     0.0\n",
       "3  We Are Many                Window Water Baby Moving      1.0     1.0\n",
       "4  We Are Many                               Wood Job!      0.0     0.0\n",
       "5  We Are Many              Zodiac: The Race Begins...      0.0     0.0\n",
       "6  We Are Many                           Убить дракона      0.0     0.0\n",
       "7  We Are Many                      Women of the Night      0.0     0.0\n",
       "8  We Are Many                               Wise Guys      0.0     0.0\n",
       "9  We Are Many                        You Wont Miss Me      0.0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Jaccard Similarity ---\n",
    "def jaccard_similarity(v1, v2):\n",
    "    # Formula:\n",
    "    #   J = Intersection(A,B) / Union(A,B)\n",
    "    A_and_B = sum(1 for (a,b) in zip(v1,v2) if a==1 and a==b) # Intersection\n",
    "    A_or_B = sum(1 for (a,b) in zip(v1,v2) if a==1 or b==1) # Union\n",
    "    return float(A_and_B) / A_or_B if A_or_B != 0 else 0.0 # Similarity\n",
    "\n",
    "# --- Cosine Similarity ---\n",
    "def cosine_similarity(v1,v2):\n",
    "    # Formula:\n",
    "    #   Sim = A·B / |A||B|\n",
    "\n",
    "    # Numerator: scalar product\n",
    "    num = sum(c1*c2 for (c1,c2) in zip(v1,v2))\n",
    "    \n",
    "    # Denominator: modules\n",
    "    mod_a = np.sqrt(sum(c1**2 for c1 in v1))\n",
    "    mod_b = np.sqrt(sum(c2**2 for c2 in v2))\n",
    "    den = mod_a * mod_b\n",
    "\n",
    "    # Similarity\n",
    "    return float(num) / float(den) if den != 0.0 else 0.0\n",
    "\n",
    "# --- User Defined Functions ---\n",
    "jaccard_udf = f.udf(lambda v1,v2: jaccard_similarity(v1,v2), FloatType())\n",
    "cosine_udf = f.udf(lambda v1,v2: cosine_similarity(v1,v2), FloatType())\n",
    "\n",
    "# Apply udf to the pairs of movies in every row\n",
    "df_similarities = df_cross.\\\n",
    "    withColumn('jaccard', jaccard_udf(f.col('left.features'), f.col('right.features'))).\\\n",
    "    withColumn('cosine', cosine_udf(f.col('left.features'), f.col('right.features'))).\\\n",
    "    select('left.title', 'right.title', 'jaccard', 'cosine')\n",
    "\n",
    "display(df_similarities.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the dataset, only the *movie_id*, *title* and *overview* will be chosen. The terms in the overviews will yield the TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Shadows in Paradise</td>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                title                                           overview\n",
       "0   2                Ariel  Taisto Kasurinen is a Finnish coal miner whose...\n",
       "1   3  Shadows in Paradise  An episode in the life of Nikander, a garbage ...\n",
       "2   5           Four Rooms  It's Ted the Bellhop's first night on the job...."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overview = df.select('id', 'title', 'overview').orderBy('id').na.drop(subset=[\"overview\"])\n",
    "display(overview.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's focus on transforming the data to make the process more efficient and vectorize the documents. As it was established before, this should include: preprocessing, tokenization, removing stopwords and computing both TF and IDF. *PySpark* can manage most of these, but for the preprocessing is required a specific behavior, thus the best approach would be to implement a custom stage for the pipeline.\n",
    "\n",
    "To create a custom stage for a pipeline one option is to create an user defined function (udf), but the preprocessing stage is slightly complex, as it must convert the text to lowercase and remove any punctuation and special characters. For this reason, a more elegant solution is to use **custom Transformers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol\n",
    "import re\n",
    "\n",
    "class TextPreprocessing(Transformer, HasInputCol, HasOutputCol):\n",
    "    '''\n",
    "    A custom Transformer which applies preprocessing to the text: convert to lowercase and remove punctuation and special characters\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_column, output_column='clean_text'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define inputCol and inputOut\n",
    "        self.inputCol = input_column\n",
    "        self.outputCol = output_column\n",
    "    \n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        # Define text transformation\n",
    "        def lowercase_and_punctuation(text):\n",
    "            lower = text.lower() # lowercase\n",
    "            return re.sub(pattern=r'[^\\w\\s]', repl='', string=lower) # remove all but words, digits and white spaces\n",
    "\n",
    "        udf_preprocess = f.udf(lambda text: lowercase_and_punctuation(text),\n",
    "                               StringType())\n",
    "\n",
    "        # Apply transformation\n",
    "        return df.withColumn(\n",
    "            self.outputCol, udf_preprocess(f.col('overview'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of them, the classes included in PySpark are enough to build a proper Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover\n",
    "\n",
    "# Text preprocessing: convert to lowercase and remove punctuation and special characters\n",
    "preprocessor = TextPreprocessing(input_column='overview', output_column='preprocessed')\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"preprocessed\", outputCol=\"words\")\n",
    "\n",
    "# Remove Stopwords\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "# TF\n",
    "count_vectorizer = CountVectorizer(\n",
    "    inputCol=\"words\", outputCol=\"rawFeatures\", minDF=2, vocabSize=500\n",
    ")\n",
    "\n",
    "hashing_tf = HashingTF(\n",
    "    inputCol='words', outputCol='rawFeatures', numFeatures=500\n",
    ")\n",
    "\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Build a Pipeline with CountVectorizer and another with HashingTF \n",
    "pipeline_CV = Pipeline(stages=[preprocessor, tokenizer, remover, count_vectorizer, idf])\n",
    "pipeline_HTF = Pipeline(stages=[preprocessor, tokenizer, remover, hashing_tf, idf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for both CountVectorizer and HashingTF—in the TF stage definition—some limits were imposed:\n",
    "\n",
    "+ Firstly and more evident, there is a maximum number of features, which is actually much lower than the default size. This is a consequence of having a large number of movies, due to the elevate time it takes to evaluate the similarities of just one movie and the rest. To solve this issue, one option would be to make a previous selection of movies with a lighter method of based on cached information, to then apply the TF-IDF method to a smaller sample.\n",
    "\n",
    "+ Secondly, with CountVectorizer exists the possibility of imposing conditions on the terms to be considered. For this matter, one of the most important one that can be done is requiring a term to appear in more than 1 (or more) documents, because if a term only appears in one document, then the similarity calculation of this element will always be zero—except for when a document is compared with itself. Furthermore, having terms that appear only in a few documents could lead to overfitting.\n",
    "\n",
    "Now, let's continue by building the models to transform the text into vectors and applying them to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features by applying the pipeline, a Hashing technique and the IDF portion\n",
    "model_CV = pipeline_CV.fit(overview)\n",
    "results_CV = model_CV.transform(overview).select('id', 'title', 'overview', 'features')\n",
    "\n",
    "model_HTF = pipeline_HTF.fit(overview)\n",
    "results_HTF = model_HTF.transform(overview).select('id', 'title', 'overview', 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute similarity of a chosen movie with the rest instead of calculating it for every possible combination, as TF-IDF is a costly method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen movie: Pirates of the Caribbean: The Curse of the Black Pearl.\n",
      "Chosen movie: Pirates of the Caribbean: The Curse of the Black Pearl.\n"
     ]
    }
   ],
   "source": [
    "# Create similarity functions\n",
    "example_movie_id = 22\n",
    "\n",
    "udf_similiarity_CV = hf.create_similarity_function(\n",
    "    spark=spark, movie_id=example_movie_id, # <-- Specify movie id to compare\n",
    "    method='cosine', results=results_CV \n",
    ")\n",
    "\n",
    "udf_similiarity_HTF = hf.create_similarity_function(\n",
    "    spark=spark, movie_id=example_movie_id, # <-- Specify movie id to compare\n",
    "    method='cosine', results=results_HTF \n",
    ")\n",
    "\n",
    "# Compute Similarities\n",
    "similarities_CV = results_CV.withColumn(\n",
    "    'similarity', udf_similiarity_CV('features')\n",
    ").\\\n",
    "    select('id', 'title', 'similarity').\\\n",
    "    orderBy('similarity', ascending=False).\\\n",
    "    filter(f.col('id') != example_movie_id)\n",
    "\n",
    "similarities_HTF = results_HTF.withColumn(\n",
    "    'similarity', udf_similiarity_HTF('features')\n",
    ").\\\n",
    "    select('id', 'title', 'similarity').\\\n",
    "    orderBy('similarity', ascending=False).\\\n",
    "    filter(f.col('id') != example_movie_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CountVectorizer Method ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>966</td>\n",
       "      <td>The Magnificent Seven</td>\n",
       "      <td>0.432751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149218</td>\n",
       "      <td>Come Dance with Me</td>\n",
       "      <td>0.429970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206183</td>\n",
       "      <td>Bad Karma</td>\n",
       "      <td>0.421883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                  title  similarity\n",
       "0     966  The Magnificent Seven    0.432751\n",
       "1  149218     Come Dance with Me    0.429970\n",
       "2  206183              Bad Karma    0.421883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 89.0 seconds.\n",
      "\n",
      "\n",
      "--- HashingTF Method ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353069</td>\n",
       "      <td>Mother's Day</td>\n",
       "      <td>0.384116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157129</td>\n",
       "      <td>Table No. 21</td>\n",
       "      <td>0.361648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37602</td>\n",
       "      <td>Oysters at Nam Kee's</td>\n",
       "      <td>0.350613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                 title  similarity\n",
       "0  353069          Mother's Day    0.384116\n",
       "1  157129          Table No. 21    0.361648\n",
       "2   37602  Oysters at Nam Kee's    0.350613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 167.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Show similarity values\n",
    "start = time.time()\n",
    "print('--- CountVectorizer Method ---')\n",
    "display(similarities_CV.limit(3).toPandas())\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {np.round(end-start)} seconds.\\n\\n')\n",
    "\n",
    "start = time.time()\n",
    "print('--- HashingTF Method ---')\n",
    "display(similarities_HTF.limit(3).toPandas())\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {np.round(end-start)} seconds.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results were similar in time and in value spread, although for *HashingTF* the first recommendation is slightly clearer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there is an alternative method for similarity calculation which involves LSH, an approximated method that only considers the closest neighbours. The function to use is the following one:\n",
    "\n",
    "```\n",
    "BucketedRandomProjectionLSH(\n",
    "    inputCol, outputCol, bucketLength, numHashTables\n",
    ")\n",
    "```\n",
    "+ *inputCol* and *outputCol* are the same as other PySpark functions (i.e. are used to indicate which column to take the data from and the column to dump the output).\n",
    "\n",
    "+ *bucketLength*: LSH creates group together hashes into the same bucket. The width of said buckets depends on this parameter, so the smaller it is, the more precision, due to the separation of hashes into different buckets. In other words, the greater this parameter, the greater the dimensionality reduction.\n",
    "\n",
    "+ *numHashTables*: In LSH, instead of relying on a single hash function, multiple ones are used to increase the chance that similar points are hashed in the same bucket. However, this also tends to introduce false positives.\n",
    "\n",
    "To choose these parameters, there are several guidelines:\n",
    "\n",
    "+ If the features are normalized *bucketLength* should be around 1 to 10, but if there is high variability, opt for 1% to 10% of the standard deviation of the data—although this requires calculating pairwise distances.\n",
    "\n",
    "+ For most applications, starting with a *numHashTables* from 10 to 25 is reasonable, but for high dimensionality data the numbers could go up around 30 to 50 hash tables.\n",
    "\n",
    "+ Finally, if the results seem irrelevant (too many false positive), either increase *bucketLength* or reduce *numHashTables*. Ans if the results are missing important matches (too many false negatives), decrease *bucketLength* or increase *nuHashTables*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSH Method ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy Ever Afters</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mother's Day</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enola Gay and the Atomic Bombing of Japan</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tour de Pharmacy</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  similarity\n",
       "0                          Happy Ever Afters       0.043\n",
       "1                               Mother's Day       0.042\n",
       "2  Enola Gay and the Atomic Bombing of Japan       0.042\n",
       "3                           Tour de Pharmacy       0.041\n",
       "4                                    Iceland       0.041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 24.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Hash words with HashingTF (with expanded vocabulary)\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "\n",
    "hashing_tf = HashingTF(\n",
    "    inputCol='words', outputCol='rawFeatures', numFeatures=1500 # <--- more words!\n",
    ")\n",
    "\n",
    "pipeline_HTF = Pipeline(stages=[preprocessor, tokenizer, remover,\n",
    "                                hashing_tf, idf])\n",
    "\n",
    "results_HTF = pipeline_HTF.fit(overview).transform(overview).\\\n",
    "    select('id', 'title', 'overview', 'features')\n",
    "\n",
    "# Apply LSH (Bucketed Random Projection LSH)\n",
    "lsh = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", \n",
    "                                  bucketLength=1, numHashTables=25)\n",
    "lsh_model = lsh.fit(results_HTF)\n",
    "\n",
    "# Find similar items for the example movie\n",
    "similar_items = lsh_model.approxNearestNeighbors(\n",
    "    results_HTF.filter(f.col('id') != example_movie_id),\n",
    "    results_HTF.filter(f.col('id') == example_movie_id).select('features').collect()[0][0],\n",
    "    numNearestNeighbors=5\n",
    ")\n",
    "\n",
    "# Show results\n",
    "def similarity_from_distance(distance):\n",
    "    return float(round(1 / (distance+1), 3))\n",
    "udf_similarity_from_distance = f.udf(lambda d: similarity_from_distance(d),\n",
    "                                     FloatType())\n",
    "\n",
    "start = time.time()\n",
    "print('--- LSH Method ---')\n",
    "\n",
    "display(similar_items.select(\"title\", \"distCol\").\\\n",
    "        withColumn('similarity', udf_similarity_from_distance(f.col('distCol'))).\\\n",
    "        select('title', 'similarity').\\\n",
    "            limit(5).toPandas())\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {np.round(end-start)} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "+ [SVD](https://machinelearningmastery.com/using-singular-value-decomposition-to-build-a-recommender-system/)\n",
    "\n",
    "**TF-IDF**\n",
    "\n",
    "+ [TF-IDF Documentation (PySpark).](https://spark.apache.org/docs/3.5.2/mllib-feature-extraction.html#tf-idf)\n",
    "\n",
    "+ [TF-IDF with CountVectorize.](https://www.analyticsvidhya.com/blog/2022/09/implementing-count-vectorizer-and-tf-idf-in-nlp-using-pyspark/)\n",
    "\n",
    "+ [TF-IDF Example.](https://runawayhorse001.github.io/LearningApacheSpark/manipulation.html)\n",
    "\n",
    "**Word2Vec**\n",
    "\n",
    "+ [What Is Word2Vec and How Does It Work?](https://swimm.io/learn/large-language-models/what-is-word2vec-and-how-does-it-work)\n",
    "\n",
    "+ [Word2Vec Wikipedia page.](https://en.wikipedia.org/wiki/Word2vec)\n",
    "\n",
    "+ [Word2Vec Documentation (PySpark).](https://spark.apache.org/docs/3.5.2/mllib-feature-extraction.html#word2vec)\n",
    "\n",
    "+ [Word2Vec: parameters and distributed training.](https://medium.com/@the.data.yoga/creating-word2vec-embeddings-on-a-large-text-corpus-with-pyspark-469007116551)\n",
    "\n",
    "+ [PySpark Sentiment Analysis with Word2Vec Embedding.](https://www.kaggle.com/code/muhammetzahitaydn/pyspark-sentiment-analysis-with-word2vec-embedding)\n",
    "\n",
    "+ [Python | Stemming words with NLTK](https://www.geeksforgeeks.org/python-stemming-words-with-nltk/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
