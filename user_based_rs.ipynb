{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f616ce7",
   "metadata": {},
   "source": [
    "# User-Based Recommender System\n",
    "\n",
    "A recommender system is an algorithm or model that takes in information about a user and suggests an item — new to them — that is likely to be of interest. There are several approaches to building such a system, and this notebook will focus on **user-based methods**. Let's begin by starting the PySpark session:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2681755e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://127.0.0.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>CBRS</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x295956cd0a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import helper_functions as hf\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import FloatType, StringType, ArrayType\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Initialize Spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CBRS\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bb8777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>858</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1      110     1.0\n",
       "1       1      147     4.5\n",
       "2       1      858     5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Movies Metadata (Load Dataset)\n",
    "df = spark.read.parquet('data/cleaned/ratings/')\n",
    "display(df.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a1aacf",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806cbfcd",
   "metadata": {},
   "source": [
    "User-Based Recommender Systems (UBRS) use the information about the preferences of similar users — or opposites — to make recommendations. The core idea is that if two users show high correlation in their preferences — positive or negative —, then one user's future preferences can be predicted based on the other user's past behavior. However, preferences not only have to refer to product ratings, but they include for example interactions with the webpage — time spent reading an article, clicked items in the current session, photos watched, etc. For this reason, an UBRS is capable of providing a custom experience even session wise, although the reliability of the data becomes the main issue.\n",
    "\n",
    "On the contrary, this kind of systems struggles with several situations:\n",
    "- **Cold Start Problem:** when there is little to no information about a customer, the recommendations become unreliable, as the user cannot show correlation with any other.\n",
    "- **Computation:** when the database is large, the process becomes expensive.\n",
    "- **Changes of opinion:** while the item data is theoretically unchanging, the customer's opinion about the rated items may vary over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7d143",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a6b2fb",
   "metadata": {},
   "source": [
    "Through cosine similarity, it is possible to compute a value based on the *angle* between two *vectors*, with the *vectors* being the user's rating of movies and the *angle* the similarity to each other — it can be positive or negative, if they are similar or opposites, but the values are kept between $[-1,1]$.\n",
    "\n",
    "The main problem with this approach are the memory issues, caused by the large number of unique movies and users in the dataset, but it is still interesting to understand this implementation and, for that reason, we will continue with a limited data set of 10 users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40ea3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out users with an Id higher than 10\n",
    "filtered_df = df.filter(f.col('userId') <= 10)\n",
    "\n",
    "# Build the user-movie matrix: \n",
    "#   userId as rows, movieId as columns and user rating as content.\n",
    "user_movie = filtered_df.groupBy('userId').pivot('movieId').agg(f.first('rating'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a90bc",
   "metadata": {},
   "source": [
    "With the memory constrains solved, the next problem is that there are users who did not rate every movie we are considering, which is the most common case, possibly because they have not watched it. This means that the user-movie matrix is filled with lots of missing data (`NA`), which cannot be easily imputed by a number, as it would assume it to be the opinion of the user about the movie.\n",
    "\n",
    "There are several approaches to manage this:\n",
    "\n",
    "- **Impute the missing values as 0:** which is simple, fast and allows for computing cosine similarity, at the expense of some reliability loss.\n",
    "\n",
    "- **Use Pearson Correlation:** which is built for comparing only co-rated items, i.e. movies rated by the two users being compared, and it is the classic Netflix approach. However, it can be unstable when there are few overlapping , and it is hard to scale efficiently in PySpark compared to vectorized cosine similarity.\n",
    "\n",
    "- **Mean centering:** by adjusting all ratings to be in the range $[-1,1]$, 0 becomes a neutral rating for a movie, so the bias introduced is less noticeable. The issue is that, when working with PySpark, missing values are a problem to create dense vectors and perform operations with them, but imputing them by the mean ratings of the users will also work.\n",
    "\n",
    "The approach we will follow next is, consequently, the use of mean centering along with imputation by the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "680b66ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43muser_movie\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_imputed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "user_movie.columns[1:] + '_imputed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f530ce5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|            features|\n",
      "+------+--------------------+\n",
      "|     1|[7.53644380168213...|\n",
      "|     6|[7.53644380168213...|\n",
      "|     3|[7.53644380168213...|\n",
      "+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_user_ratings(user_movie = user_movie):\n",
    "    from pyspark.ml.feature import Imputer\n",
    "    from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "    # Impute missing values as the mean for every user\n",
    "    inputCols = user_movie.columns[1:]\n",
    "    outputCols = [col_name + '_imputed' for col_name in inputCols]\n",
    "\n",
    "    imputer = Imputer(\n",
    "        inputCols=inputCols, outputCols=outputCols, strategy='mean'\n",
    "    )\n",
    "\n",
    "    # Create a dense vector representation for each user\n",
    "    vector_assembler = VectorAssembler(\n",
    "        inputCols=outputCols, outputCol='vectors'\n",
    "    )\n",
    "\n",
    "    # Mean Centering and Normalization\n",
    "    scaler = StandardScaler(withMean=True, withStd=True,\n",
    "                            inputCol='vectors', outputCol='features')\n",
    "\n",
    "    # Pipeline\n",
    "    p = Pipeline(stages=[imputer, vector_assembler, scaler]).fit(user_movie)\n",
    "\n",
    "    # Transform data\n",
    "    user_vector = p.transform(user_movie).select('userId','features')\n",
    "    user_vector.show(3, truncate=True)\n",
    "\n",
    "    return user_vector\n",
    "\n",
    "user_vector = prepare_user_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd0d2b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>features</th>\n",
       "      <th>userId</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>6</td>\n",
       "      <td>[7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>3</td>\n",
       "      <td>[7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>5</td>\n",
       "      <td>[7.536443801682132e-15, 0.0, 2.121320343559642...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                                           features  userId  \\\n",
       "0       1  [7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....       6   \n",
       "1       1  [7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....       3   \n",
       "2       1  [7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....       5   \n",
       "\n",
       "                                            features  \n",
       "0  [7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....  \n",
       "1  [7.536443801682132e-15, 0.0, 0.0, 0.0, 0.0, 0....  \n",
       "2  [7.536443801682132e-15, 0.0, 2.121320343559642...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cross Join: cartesian product to form pairs.\n",
    "# Allow repeated pairs — (1,2) and (2,1) —, so that left.userId\n",
    "# can always be the target user and right.userId the neighbors.\n",
    "# Filter out pairs with itself — (1,1), (2,2), etc.\n",
    "user_cross = user_vector.alias('left').\\\n",
    "    crossJoin(user_vector.alias('right')).\\\n",
    "    filter(f.col('left.userId') != f.col('right.userId'))\n",
    "\n",
    "display(user_cross.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb799ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId_1</th>\n",
       "      <th>userId_2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.393876e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.185532e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.157351e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.120754e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.896361e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-9.855314e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.094177e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.393876e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.207132e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.393876e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId_1  userId_2    similarity\n",
       "0         1         6 -1.393876e-16\n",
       "1         1         3 -2.185532e-01\n",
       "2         1         5  4.157351e-02\n",
       "3         1         9 -1.120754e-01\n",
       "4         1         4 -3.896361e-02\n",
       "5         1         8 -9.855314e-02\n",
       "6         1         7 -5.094177e-01\n",
       "7         1        10 -1.393876e-16\n",
       "8         1         2 -1.207132e-16\n",
       "9         6         1 -1.393876e-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cosine Similarity UDF\n",
    "def cosine_similarity(v1,v2):\n",
    "    # Formula:\n",
    "    #   Sim = A·B / |A||B|\n",
    "\n",
    "    # Numerator: scalar product\n",
    "    num = sum(c1*c2 for (c1,c2) in zip(v1,v2))\n",
    "    \n",
    "    # Denominator: modules\n",
    "    mod_a = np.sqrt(sum(c1**2 for c1 in v1))\n",
    "    mod_b = np.sqrt(sum(c2**2 for c2 in v2))\n",
    "    den = mod_a * mod_b\n",
    "\n",
    "    # Similarity\n",
    "    return float(num) / float(den) if den != 0.0 else 0.0\n",
    "\n",
    "cosine_udf = f.udf(lambda v1,v2: cosine_similarity(v1,v2), FloatType())\n",
    "\n",
    "# Apply udf to the pairs of movies in every row\n",
    "df_similarities = user_cross.\\\n",
    "    withColumn('similarity', cosine_udf(f.col('left.features'), f.col('right.features'))).\\\n",
    "    select(f.col('left.userId').alias('userId_1'), \n",
    "           f.col('right.userId').alias('userId_2'), \n",
    "           'similarity')\n",
    "\n",
    "display(df_similarities.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0650b",
   "metadata": {},
   "source": [
    "In User-Based Recommender Systems, the last step includes computing neighbors' to discover which movies to recommend using collaboration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd37ff83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId_1</th>\n",
       "      <th>userId_2</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.157351e-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.207132e-16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.393876e-16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.393876e-16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.896361e-02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.620802e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1.762172e-15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9.362936e-16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.845925e-16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.845925e-16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId_1  userId_2    similarity  rank\n",
       "0         1         5  4.157351e-02     1\n",
       "1         1         2 -1.207132e-16     2\n",
       "2         1         6 -1.393876e-16     3\n",
       "3         1        10 -1.393876e-16     4\n",
       "4         1         4 -3.896361e-02     5\n",
       "5         2         8  1.620802e-01     1\n",
       "6         2         9  1.762172e-15     2\n",
       "7         2         7  9.362936e-16     3\n",
       "8         2         6  3.845925e-16     4\n",
       "9         2        10  3.845925e-16     5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "# Create data window:\n",
    "# Assume left.userId is the target user and right.userId the neighbor\n",
    "window = Window.\\\n",
    "    orderBy(f.col('similarity').desc()).\\\n",
    "    partitionBy('userId_1')\n",
    "    \n",
    "# Get Top N most similar neighbor for each left.userId\n",
    "top_n_neighbors = df_similarities.\\\n",
    "    withColumn('rank', f.row_number().over(window)).\\\n",
    "    filter(f.col('rank') <= 5)\n",
    "\n",
    "display(top_n_neighbors.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940f8b7",
   "metadata": {},
   "source": [
    "Join the rankings of the neighbors (pair wise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8280f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targetUser</th>\n",
       "      <th>movieId</th>\n",
       "      <th>similarity</th>\n",
       "      <th>neighbor_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>110</td>\n",
       "      <td>-0.098553</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>-0.038964</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   targetUser  movieId  similarity  neighbor_rating\n",
       "0           8      110   -0.098553              1.0\n",
       "1           5      110    0.041574              1.0\n",
       "2           4      110   -0.038964              1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neighbor_ranking = top_n_neighbors.join(\n",
    "    other=df,\n",
    "    on=(top_n_neighbors.userId_2 == df.userId),\n",
    "    how='inner'\n",
    ").select(\n",
    "    f.col('userId_1').alias('targetUser'),\n",
    "    f.col('movieId'),\n",
    "    f.col('similarity'),\n",
    "    f.col('rating').alias('neighbor_rating')\n",
    ")\n",
    "\n",
    "display(neighbor_ranking.limit(3).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aad182",
   "metadata": {},
   "source": [
    "However, we are only interested in the movies that the target user has not seen yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c793e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movies seen (already rated by the target user)\n",
    "targetUser_rated = df.select(f.col('userId').alias('targetUser'), 'movieId')\n",
    "\n",
    "# Keep only unseen movies\n",
    "unseen_movies = neighbor_ranking.join(\n",
    "    other=targetUser_rated,\n",
    "    on=['targetUser', 'movieId'],\n",
    "    how='left_anti' # drop movies that appear in both tables\n",
    ")\n",
    "\n",
    "# Compute weighted rating and its average\n",
    "recommendations = unseen_movies.withColumn(\n",
    "    colName='weighted_rating',\n",
    "    col = f.col('similarity') * f.col('neighbor_rating')\n",
    ").groupby(\n",
    "    'targetUser', 'movieId'\n",
    ").agg(\n",
    "    f.expr('sum(weighted_rating) / sum(similarity)').\\\n",
    "        alias('predicted_score')\n",
    ")\n",
    "\n",
    "# Get the top K recommendations per user\n",
    "window = Window.partitionBy('targetUser').orderBy(f.col('predicted_score').desc())\n",
    "\n",
    "top_k_recommendations = recommendations.\\\n",
    "    withColumn('rank', f.row_number().over(window)).\\\n",
    "    filter(f.col('rank') <= 5)\n",
    "\n",
    "display(top_k_recommendations.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad179fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
